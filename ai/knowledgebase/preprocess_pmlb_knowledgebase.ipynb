{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pennai ML options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml: BernoulliNB\n",
      "param: alpha , options: [0.001, 0.01, 0.1, 1, 10, 100]\n",
      "param: binarize , options: [0, 0.25, 0.5, 0.75, 1]\n",
      "param: fit_prior , options: ['true', 'false']\n",
      "ml: GaussianNB\n",
      "ml: MultinomialNB\n",
      "param: alpha , options: [0.001, 0.01, 0.1, 1.0, 10, 100]\n",
      "param: fit_prior , options: ['true', 'false']\n",
      "ml: DecisionTreeClassifier\n",
      "param: criterion , options: ['gini', 'entropy']\n",
      "param: max_depth , options: [2, 4, 6, 8, 'None']\n",
      "param: min_samples_split , options: [2, 5, 10, 20]\n",
      "param: min_samples_leaf , options: [1, 5, 10, 20]\n",
      "param: min_weight_fraction_leaf , options: [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
      "param: max_features , options: ['sqrt', 'log2', 'None']\n",
      "ml: ExtraTreesClassifier\n",
      "param: n_estimators , options: [100, 250]\n",
      "param: criterion , options: ['gini', 'entropy']\n",
      "param: max_features , options: ['sqrt', 'log2', 'None']\n",
      "param: min_samples_split , options: [2, 5, 10, 20]\n",
      "param: min_samples_leaf , options: [1, 5, 10, 20]\n",
      "param: bootstrap , options: ['true', 'false']\n",
      "ml: GradientBoostingClassifier\n",
      "param: n_estimators , options: [100, 250]\n",
      "param: learning_rate , options: [0.01, 0.1, 1]\n",
      "param: max_depth , options: [1, 5, 10]\n",
      "param: min_samples_split , options: [2, 5, 10, 20]\n",
      "param: min_samples_leaf , options: [1, 5, 10, 20]\n",
      "param: subsample , options: [0.5, 1]\n",
      "param: max_features , options: ['sqrt', 'log2']\n",
      "param: loss , options: ['deviance', 'exponential']\n",
      "ml: KNeighborsClassifier\n",
      "param: n_neighbors , options: [1, 3, 5, 7, 9, 11]\n",
      "param: weights , options: ['uniform', 'distance']\n",
      "param: p , options: [1, 2]\n",
      "ml: LinearSVC\n",
      "param: penalty , options: ['l1', 'l2']\n",
      "param: loss , options: ['hinge', 'squared_hinge']\n",
      "param: dual , options: ['true', 'false']\n",
      "param: tol , options: [1e-05, 0.0001, 0.001, 0.01, 0.1]\n",
      "param: C , options: [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 25]\n",
      "ml: LogisticRegression\n",
      "param: penalty , options: ['l1', 'l2']\n",
      "param: C , options: [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 25]\n",
      "param: dual , options: ['true', 'false']\n",
      "param: fit_intercept , options: ['true', 'false']\n",
      "ml: RandomForestClassifier\n",
      "param: n_estimators , options: [100, 250]\n",
      "param: criterion , options: ['gini', 'entropy']\n",
      "param: max_features , options: ['sqrt', 'log2']\n",
      "param: min_samples_split , options: [2, 5, 10, 20]\n",
      "param: min_samples_leaf , options: [1, 5, 10, 20]\n",
      "param: bootstrap , options: ['true', 'false']\n",
      "param: min_weight_fraction_leaf , options: [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
      "ml: SVC\n",
      "param: kernel , options: ['poly', 'rbf']\n",
      "param: tol , options: [1e-05, 0.0001, 0.001, 0.01, 0.1]\n",
      "param: C , options: [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 25]\n",
      "param: gamma , options: [0.01, 0.1, 0.5, 1.0, 10.0, 100.0, 50.0]\n",
      "param: degree , options: [2, 3]\n",
      "param: coef0 , options: [0.0, 0.1, 0.5, 1.0, 10, 50, 100]\n",
      "pennai_ml_opts: 11\n",
      "BernoulliNB options: 60\n",
      "GaussianNB options: 1\n",
      "MultinomialNB options: 12\n",
      "DecisionTreeClassifier options: 6336\n",
      "ExtraTreesClassifier options: 384\n",
      "GradientBoostingClassifier options: 2304\n",
      "KNeighborsClassifier options: 24\n",
      "LinearSVC options: 320\n",
      "LogisticRegression options: 64\n",
      "RandomForestClassifier options: 2816\n",
      "SVC options: 7840\n"
     ]
    }
   ],
   "source": [
    "import json                                                                          \n",
    "import numpy as np                                                                   \n",
    "from json import JSONDecoder                                                         \n",
    "from functools import partial                                                        \n",
    "                                                                                     \n",
    "path = 'projects_newlines.json'                                \n",
    "data,alldata=[],[]                                                                   \n",
    "with open(path) as f:                                                                \n",
    "    for line in f:                                                                   \n",
    "        alldata.append(json.loads(line))                                             \n",
    "    # for data in json_parse(f):                                                     \n",
    "    #     print(data)                                                                \n",
    "    #     alldata.append(data)                                                       \n",
    "pennai_ml_opts = {}                                                                         \n",
    "import pdb                                                                           \n",
    "from sklearn.model_selection import ParameterGrid                                    \n",
    "                                                                                     \n",
    "original_pennai_ml_opts = {}\n",
    "for d in alldata:                                                                    \n",
    "    print('ml:',d['name'])                                                           \n",
    "                                                                                     \n",
    "    params = d['schema'].keys()                                                      \n",
    "    choices = {}                                                                     \n",
    "    for p in params:                               \n",
    "        if 'values' in d['schema'][p]['ui']:\n",
    "            choices[p] = d['schema'][p]['ui']['values']                                 \n",
    "        else:\n",
    "            choices[p] = d['schema'][p]['ui']['choices']                                 \n",
    "        print('param:',p,', options:',choices[p])\n",
    "    # add None to DecisionTreeClassifier's max_depth option.\n",
    "    if d['name'] == 'DecisionTreeClassifier':\n",
    "        choices['max_depth'].append(None)\n",
    "#     pdb.set_trace()\n",
    "    original_pennai_ml_opts[d['name']] = choices.keys()\n",
    "    param_grid = list(ParameterGrid(choices))                                        \n",
    "#     print('param_grid contains',len(param_grid),'options')                           \n",
    "    pennai_ml_opts[d['name']] = param_grid                                                  \n",
    "print('pennai_ml_opts:',len(pennai_ml_opts))      \n",
    "for key in pennai_ml_opts.keys():\n",
    "    print(key,'options:',len(pennai_ml_opts[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method to extend ML parameter options with default parameters if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "default_params = {}\n",
    "default_params['DecisionTreeClassifier'] = DecisionTreeClassifier().get_params()\n",
    "default_params['RandomForestClassifier'] = RandomForestClassifier().get_params()\n",
    "default_params['ExtraTreesClassifier'] = ExtraTreesClassifier().get_params()\n",
    "default_params['GradientBoostingClassifier'] = GradientBoostingClassifier().get_params()\n",
    "default_params['BernoulliNB'] = BernoulliNB().get_params()\n",
    "default_params['GaussianNB'] = GaussianNB().get_params()\n",
    "default_params['MultinomialNB'] = MultinomialNB().get_params()\n",
    "default_params['KNeighborsClassifier'] = KNeighborsClassifier().get_params()\n",
    "default_params['LinearSVC'] = LinearSVC().get_params()\n",
    "default_params['SVC'] = SVC().get_params()\n",
    "default_params['LogisticRegression'] = LogisticRegression().get_params()\n",
    "\n",
    "def extend_params(ml,params):\n",
    "    missing_params = [(k,v) for k,v in default_params[ml].items() if k not in params]\n",
    "    for k,v in missing_params:\n",
    "        params[k] = v\n",
    "    return params\n",
    "\n",
    "##\n",
    "# function to lower case strings\n",
    "def fix_params(params):\n",
    "    for k,v in params.items():\n",
    "        if type(v) is str:\n",
    "            if v == 'true':\n",
    "                params[k] = True\n",
    "            elif v == 'false':\n",
    "                params[k] = False\n",
    "            elif v == 'None':\n",
    "                params[k] == None\n",
    "            else:\n",
    "                params[k] = v.lower() \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pennai_ml_opts_ext = {}\n",
    "for k,v in pennai_ml_opts.items():\n",
    "    pennai_ml_opts_ext[k] = []\n",
    "    for params in v:\n",
    "        pennai_ml_opts_ext[k].append(extend_params(k,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pmlb results\n",
    "filter out classifiers not in PennAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bill/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             dataset          classifier  \\\n",
      "0  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "1  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "2  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "3  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "4  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "\n",
      "                             parameters  accuracy   macrof1 bal_accuracy  \n",
      "0    learning_rate=0.01,n_estimators=10  0.479375  0.470857   0.479375.1  \n",
      "1   learning_rate=0.01,n_estimators=100  0.476875  0.476497     0.476875  \n",
      "2  learning_rate=0.01,n_estimators=1000  0.488125  0.488115     0.488125  \n",
      "3    learning_rate=0.01,n_estimators=50  0.483750  0.483652      0.48375  \n",
      "4   learning_rate=0.01,n_estimators=500  0.495625  0.495609     0.495625  \n",
      "loaded  166 datasets and  13 classifiers\n",
      "datasets ( 166 )\n",
      "classifiers ( 6 ): ['DecisionTreeClassifier' 'GradientBoostingClassifier'\n",
      " 'KNeighborsClassifier' 'LogisticRegression' 'RandomForestClassifier'\n",
      " 'SVC']\n",
      "parameters for  DecisionTreeClassifier ( 154 ): ['min_weight_fraction_leaf=0.0,max_features=0.1,criterion=entropy'\n",
      " 'min_weight_fraction_leaf=0.0,max_features=0.1,criterion=gini'\n",
      " 'min_weight_fraction_leaf=0.0,max_features=0.25,criterion=entropy'\n",
      " 'min_weight_fraction_leaf=0.0,max_features=0.25,criterion=gini'\n",
      " 'min_weight_fraction_leaf=0.0,max_features=0.5,criterion=entropy']\n",
      "parameters for  GradientBoostingClassifier ( 6301 ): ['loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.2'\n",
      " 'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.3'\n",
      " 'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.4'\n",
      " 'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.5'\n",
      " 'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.6']\n",
      "parameters for  KNeighborsClassifier ( 54 ): ['n_neighbors=1,weights=distance' 'n_neighbors=1,weights=uniform'\n",
      " 'n_neighbors=10,weights=distance' 'n_neighbors=10,weights=uniform'\n",
      " 'n_neighbors=100,weights=distance']\n",
      "parameters for  LogisticRegression ( 240 ): ['C=0.5,penalty=l1,fit_intercept=False,dual=False,'\n",
      " 'C=0.5,penalty=l1,fit_intercept=True,dual=False,'\n",
      " 'C=0.5,penalty=l2,fit_intercept=False,dual=False,'\n",
      " 'C=0.5,penalty=l2,fit_intercept=False,dual=True,'\n",
      " 'C=0.5,penalty=l2,fit_intercept=True,dual=False,']\n",
      "parameters for  RandomForestClassifier ( 770 ): ['n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.1,criterion=entropy'\n",
      " 'n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.1,criterion=gini'\n",
      " 'n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.25,criterion=entropy'\n",
      " 'n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.25,criterion=gini'\n",
      " 'n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.5,criterion=entropy']\n",
      "parameters for  SVC ( 1239 ): ['C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=0.0,'\n",
      " 'C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=0.1,'\n",
      " 'C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=0.5,'\n",
      " 'C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=1.0,'\n",
      " 'C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=10.0,']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../../mock_experiment/sklearn-benchmark5-data-edited.tsv.gz', sep='\\t', names=['dataset',\n",
    "                                                                     'classifier',\n",
    "                                                                     'parameters',\n",
    "                                                                     'accuracy', \n",
    "                                                                     'macrof1',\n",
    "                                                                     'bal_accuracy']).fillna('')\n",
    "print(data.head())\n",
    "data['accuracy'] = data['accuracy'].apply(lambda x: round(x, 3))\n",
    "print('loaded ',data['dataset'].unique().shape[0],'datasets and ', data['classifier'].unique().shape[0],'classifiers')\n",
    "# subset data to classifiers used in PennAI\n",
    "pennai_classifiers = ['LogisticRegression', 'RandomForestClassifier', 'SVC', \n",
    "                      'KNeighborsClassifier', 'DecisionTreeClassifier', 'GradientBoostingClassifier']\n",
    "mask = np.array([c in pennai_classifiers for c in data['classifier'].values])\n",
    "data = data.loc[mask,:]\n",
    "print('datasets (',len(data['dataset'].unique()),')')\n",
    "print('classifiers (',len(data['classifier'].unique()),'):',data['classifier'].unique())\n",
    "for ml, df_g in data.groupby('classifier'):\n",
    "    print('parameters for ',ml,'(',len(df_g['parameters'].unique()),'):',df_g['parameters'].unique()[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.2',\n",
       "       'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.3',\n",
       "       'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.4',\n",
       "       ...,\n",
       "       'loss=exponential,learning_rate=50.0,n_estimators=500,max_depth=None,max_features=0.9',\n",
       "       'loss=exponential,learning_rate=50.0,n_estimators=500,max_depth=None,max_features=log2',\n",
       "       'loss=exponential,learning_rate=50.0,n_estimators=500,max_depth=None,max_features=sqrt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.classifier=='GradientBoostingClassifier']['parameters'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert from sklearn-style parameter formatting to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macrof1</th>\n",
       "      <th>bal_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.507488</td>\n",
       "      <td>0.5075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.476040</td>\n",
       "      <td>0.47625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.506832</td>\n",
       "      <td>0.506875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.489993</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512497</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dataset  \\\n",
       "175  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "176  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "177  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "178  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "179  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "\n",
       "                 classifier  \\\n",
       "175  DecisionTreeClassifier   \n",
       "176  DecisionTreeClassifier   \n",
       "177  DecisionTreeClassifier   \n",
       "178  DecisionTreeClassifier   \n",
       "179  DecisionTreeClassifier   \n",
       "\n",
       "                                            parameters  accuracy   macrof1  \\\n",
       "175  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.507  0.507488   \n",
       "176  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.476  0.476040   \n",
       "177  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.507  0.506832   \n",
       "178  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.490  0.489993   \n",
       "179  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.512  0.512497   \n",
       "\n",
       "    bal_accuracy  \n",
       "175       0.5075  \n",
       "176      0.47625  \n",
       "177     0.506875  \n",
       "178         0.49  \n",
       "179       0.5125  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_params(p):\n",
    "    fixed_params = {k:v for k,v in [tuple(ps.split('=')) for ps in filter(None, p.split(','))]}\n",
    "    for k,v in fixed_params.items():\n",
    "        try:\n",
    "            fixed_params[k] = int(v)\n",
    "        except ValueError:\n",
    "            try:     \n",
    "                fixed_params[k] = float(v)\n",
    "            except ValueError:\n",
    "                if fixed_params[k] == 'None':\n",
    "                    fixed_params[k] = None \n",
    "                else:\n",
    "                    fixed_params[k] = str(v).lower()\n",
    "                pass\n",
    "    return fixed_params\n",
    "# datanew = data.copy()\n",
    "data_formatted = data.copy()\n",
    "data_formatted['parameters'] = data_formatted['parameters'].apply(lambda x: fix_params(x))\n",
    "\n",
    "data_formatted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add default parameters to parameter dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df_extend_params(x):\n",
    "#     print(x)\n",
    "    x.parameters = extend_params(x.classifier,x.parameters)\n",
    "    return x\n",
    "data_formatted_ext = data_formatted.copy()\n",
    "data_formatted_ext = data_formatted_ext.apply(lambda x: df_extend_params(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macrof1</th>\n",
       "      <th>bal_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.507488</td>\n",
       "      <td>0.5075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.476040</td>\n",
       "      <td>0.47625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.506832</td>\n",
       "      <td>0.506875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.489993</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512497</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dataset  \\\n",
       "175  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "176  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "177  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "178  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "179  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "\n",
       "                 classifier  \\\n",
       "175  DecisionTreeClassifier   \n",
       "176  DecisionTreeClassifier   \n",
       "177  DecisionTreeClassifier   \n",
       "178  DecisionTreeClassifier   \n",
       "179  DecisionTreeClassifier   \n",
       "\n",
       "                                            parameters  accuracy   macrof1  \\\n",
       "175  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.507  0.507488   \n",
       "176  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.476  0.476040   \n",
       "177  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.507  0.506832   \n",
       "178  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.490  0.489993   \n",
       "179  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.512  0.512497   \n",
       "\n",
       "    bal_accuracy  \n",
       "175       0.5075  \n",
       "176      0.47625  \n",
       "177     0.506875  \n",
       "178         0.49  \n",
       "179       0.5125  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_formatted_ext.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter out any parameter combinations that PennAI can't recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfiltered: 1113067 results with 8758 unique parameters\n",
      "calculating mask...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1113067it [03:49, 4860.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with mask\n",
      "filtered data has 80632 results with 623 unique parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macrof1</th>\n",
       "      <th>bal_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.479267</td>\n",
       "      <td>0.479375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.502493</td>\n",
       "      <td>0.5025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498109</td>\n",
       "      <td>0.498125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.0, 'max_feature...</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503109</td>\n",
       "      <td>0.503125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_weight_fraction_leaf': 0.05, 'max_featur...</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.515156</td>\n",
       "      <td>0.51625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dataset  \\\n",
       "185  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "186  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "187  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "188  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "199  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "\n",
       "                 classifier  \\\n",
       "185  DecisionTreeClassifier   \n",
       "186  DecisionTreeClassifier   \n",
       "187  DecisionTreeClassifier   \n",
       "188  DecisionTreeClassifier   \n",
       "199  DecisionTreeClassifier   \n",
       "\n",
       "                                            parameters  accuracy   macrof1  \\\n",
       "185  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.479  0.479267   \n",
       "186  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.502  0.502493   \n",
       "187  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.498  0.498109   \n",
       "188  {'min_weight_fraction_leaf': 0.0, 'max_feature...     0.503  0.503109   \n",
       "199  {'min_weight_fraction_leaf': 0.05, 'max_featur...     0.516  0.515156   \n",
       "\n",
       "    bal_accuracy  \n",
       "185     0.479375  \n",
       "186       0.5025  \n",
       "187     0.498125  \n",
       "188     0.503125  \n",
       "199      0.51625  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def valid_param_combo(ml, params):\n",
    "    if params in pennai_ml_opts_ext[ml]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "print('unfiltered:',len(data_formatted_ext),'results with',\n",
    "     len(data_formatted_ext.parameters.apply(str).unique()),'unique parameters')\n",
    "data_formatted_ext_filtered = data_formatted_ext#.loc[data_formatted_ext.classifier=='SVC']\n",
    "print('calculating mask...')\n",
    "mask = []\n",
    "from tqdm import tqdm\n",
    "for _, row in tqdm(data_formatted_ext_filtered.iterrows()):\n",
    "    mask.append(valid_param_combo(row['classifier'],row['parameters']) )\n",
    "print('done with mask')\n",
    "# mask = mask | data_formatted_ext_filtered.classifier=='LogisticRegression'\n",
    "data_formatted_ext_filtered = data_formatted_ext_filtered.loc[mask]\n",
    "print('filtered data has',len(data_formatted_ext_filtered),'results with',\n",
    "     len(data_formatted_ext_filtered.parameters.apply(str).unique()),'unique parameters')\n",
    "data_formatted_ext_filtered.head()\n",
    "# data_filtered = data.loc[lambda x: valid_param_combo(i['classifier'],i['parameters']) for i in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier unique params combos: 32\n",
      "GradientBoostingClassifier unique params combos: 36\n",
      "KNeighborsClassifier unique params combos: 12\n",
      "LogisticRegression unique params combos: 18\n",
      "SVC unique params combos: 525\n",
      "623 unique algorithm/parameter combinations\n"
     ]
    }
   ],
   "source": [
    "for clf, dfg in data_formatted_ext_filtered.groupby('classifier'):\n",
    "    print(clf,'unique params combos:',len(dfg.parameters.apply(str).unique()))\n",
    "alg_params = data_formatted_ext_filtered['classifier']+'|'+data_formatted_ext_filtered['parameters'].apply(str)\n",
    "print(len(alg_params.unique()),'unique algorithm/parameter combinations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-prune parameters from knowledgebase that were added as defaults (not in PennAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prune_params(x):\n",
    "#     pdb.set_trace()\n",
    "    ml = x.classifier\n",
    "    params = x.parameters\n",
    "    param_opts = original_pennai_ml_opts[ml]\n",
    "    x.parameters = {k:v for k,v in params.items() if k in param_opts}\n",
    "    return x \n",
    "data_formatted_ext_filtered_pruned = data_formatted_ext_filtered.copy()\n",
    "data_formatted_ext_filtered_pruned = data_formatted_ext_filtered_pruned.apply(\n",
    "    lambda x: prune_params(x),axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn parameters into sorted lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier unique params combos: 32\n",
      "GradientBoostingClassifier unique params combos: 36\n",
      "KNeighborsClassifier unique params combos: 12\n",
      "LogisticRegression unique params combos: 18\n",
      "SVC unique params combos: 525\n",
      "623 unique algorithm/parameter combinations\n"
     ]
    }
   ],
   "source": [
    "for clf, dfg in data_formatted_ext_filtered_pruned.groupby('classifier'):\n",
    "    print(clf,'unique params combos:',len(dfg.parameters.apply(str).unique()))\n",
    "alg_params = (data_formatted_ext_filtered_pruned['classifier']+'|'\n",
    "              +data_formatted_ext_filtered_pruned['parameters'].apply(str))\n",
    "print(len(alg_params.unique()),'unique algorithm/parameter combinations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 datasets left\n"
     ]
    }
   ],
   "source": [
    "# Remove big files since their metafeatures take forever to load\n",
    "data_formatted_ext_filtered_pruned_small = data_formatted_ext_filtered_pruned.copy()\n",
    "#datasets to remove:\n",
    "big_datasets = ['poker', 'kddcup', 'sleep', 'fars', 'mnist'] \n",
    "# , 'connect-4', 'shuttle', 'adult', 'krkopt', \n",
    "#                 'letter', 'magic', 'nursery', 'pendigits', 'coil2000', 'agaricus-lepiota','optdigits']\n",
    "mask = np.array([d not in big_datasets for d in data_formatted_ext_filtered_pruned_small['dataset'].values])\n",
    "data_formatted_ext_filtered_pruned_small  = data_formatted_ext_filtered_pruned_small.loc[mask,:]\n",
    "print(len(data_formatted_ext_filtered_pruned_small['dataset'].unique()),'datasets left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write modified data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80302 total results\n"
     ]
    }
   ],
   "source": [
    "print(len(data_formatted_ext_filtered_pruned_small),'total results')\n",
    "data_formatted_ext_filtered_pruned_small.rename(columns={'classifier':'algorithm'},inplace=True)\n",
    "data_formatted_ext_filtered_pruned_small.to_csv('sklearn-benchmark5-data-knowledgebase.tsv.gz',\n",
    "                                                compression='gzip',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a small knowledge base for testing\n",
    "test_data = data_formatted_ext_filtered_pruned_small.sample(frac=0.1)\n",
    "data_formatted_ext_filtered_pruned_small.to_csv('sklearn-benchmark5-data-knowledgebase-small.tsv.gz',\n",
    "                                                compression='gzip',index=False,sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
