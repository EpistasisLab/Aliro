{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pennai ML options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json                                                                          \n",
    "import numpy as np                                                                   \n",
    "from json import JSONDecoder                                                         \n",
    "from functools import partial                                                        \n",
    "                                                                         \n",
    "alldata= json.load(open('../../../dockers/dbmongo/files/projects.json'),encoding=\"utf-8\")\n",
    "\n",
    "# path = 'projects_newlines.json'                                \n",
    "# data,alldata=[],[]                                                                   \n",
    "# with open(path) as f:                                                                \n",
    "#     for line in f:                                                                   \n",
    "#         alldata.append(json.loads(line))                                             \n",
    "#     # for data in json_parse(f):                                                     \n",
    "#     #     print(data)                                                                \n",
    "#     #     alldata.append(data)                                                       \n",
    "pennai_ml_opts = {}                                                                         \n",
    "import pdb                                                                           \n",
    "from sklearn.model_selection import ParameterGrid                                    \n",
    "                                                                                     \n",
    "original_pennai_ml_opts = {}\n",
    "for d in alldata:                                                                    \n",
    "    print('ml:',d['name'])                                                           \n",
    "                                                                                     \n",
    "    params = d['schema'].keys()                                                      \n",
    "    choices = {}                                                                     \n",
    "    for p in params:                               \n",
    "        if 'values' in d['schema'][p]['ui']:\n",
    "            choices[p] = d['schema'][p]['ui']['values']                                 \n",
    "        else:\n",
    "            choices[p] = d['schema'][p]['ui']['choices']                                 \n",
    "        print('param:',p,', options:',choices[p])\n",
    "    # add None to DecisionTreeClassifier's max_depth option.\n",
    "    if d['name'] == 'DecisionTreeClassifier':\n",
    "        choices['max_depth'].append(None)\n",
    "#     pdb.set_trace()\n",
    "    original_pennai_ml_opts[d['name']] = choices.keys()\n",
    "    param_grid = list(ParameterGrid(choices))                                        \n",
    "#     print('param_grid contains',len(param_grid),'options')                           \n",
    "    pennai_ml_opts[d['name']] = param_grid                                                  \n",
    "print('pennai_ml_opts:',len(pennai_ml_opts))      \n",
    "for key in pennai_ml_opts.keys():\n",
    "    print(key,'options:',len(pennai_ml_opts[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method to extend ML parameter options with default parameters if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "default_params = {}\n",
    "default_params['DecisionTreeClassifier'] = DecisionTreeClassifier().get_params()\n",
    "default_params['RandomForestClassifier'] = RandomForestClassifier().get_params()\n",
    "default_params['ExtraTreesClassifier'] = ExtraTreesClassifier().get_params()\n",
    "default_params['GradientBoostingClassifier'] = GradientBoostingClassifier().get_params()\n",
    "default_params['BernoulliNB'] = BernoulliNB().get_params()\n",
    "default_params['GaussianNB'] = GaussianNB().get_params()\n",
    "default_params['MultinomialNB'] = MultinomialNB().get_params()\n",
    "default_params['KNeighborsClassifier'] = KNeighborsClassifier().get_params()\n",
    "default_params['LinearSVC'] = LinearSVC().get_params()\n",
    "default_params['SVC'] = SVC().get_params()\n",
    "default_params['LogisticRegression'] = LogisticRegression().get_params()\n",
    "\n",
    "def extend_params(ml,params):\n",
    "    missing_params = [(k,v) for k,v in default_params[ml].items() if k not in params]\n",
    "    for k,v in missing_params:\n",
    "        params[k] = v\n",
    "    return params\n",
    "\n",
    "##\n",
    "# function to lower case strings\n",
    "def fix_params(params):\n",
    "    for k,v in params.items():\n",
    "        if type(v) is str:\n",
    "            if v == 'true':\n",
    "                params[k] = True\n",
    "            elif v == 'false':\n",
    "                params[k] = False\n",
    "            elif v == 'None':\n",
    "                params[k] == None\n",
    "            else:\n",
    "                params[k] = v.lower() \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pennai_ml_opts_ext = {}\n",
    "for k,v in pennai_ml_opts.items():\n",
    "    pennai_ml_opts_ext[k] = []\n",
    "    for params in v:\n",
    "        pennai_ml_opts_ext[k].append(extend_params(k,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pmlb results\n",
    "filter out classifiers not in PennAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../../../mock_experiment/sklearn-benchmark5-data-edited.tsv.gz', sep='\\t').fillna('')\n",
    "print(data.head())\n",
    "data['accuracy'] = data['accuracy'].apply(lambda x: round(x, 3))\n",
    "print('loaded ',data['dataset'].unique().shape[0],'datasets and ', data['classifier'].unique().shape[0],'classifiers')\n",
    "# subset data to classifiers used in PennAI\n",
    "pennai_classifiers = ['LogisticRegression', 'RandomForestClassifier', 'SVC', \n",
    "                      'KNeighborsClassifier', 'DecisionTreeClassifier', 'GradientBoostingClassifier']\n",
    "mask = np.array([c in pennai_classifiers for c in data['classifier'].values])\n",
    "data = data.loc[mask,:]\n",
    "print('datasets (',len(data['dataset'].unique()),')')\n",
    "print('classifiers (',len(data['classifier'].unique()),'):',data['classifier'].unique())\n",
    "for ml, df_g in data.groupby('classifier'):\n",
    "    print('parameters for ',ml,'(',len(df_g['parameters'].unique()),'):',df_g['parameters'].unique()[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.classifier=='GradientBoostingClassifier']['parameters'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert from sklearn-style parameter formatting to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_params(p):\n",
    "    fixed_params = {k:v for k,v in [tuple(ps.split('=')) for ps in filter(None, p.split(','))]}\n",
    "    for k,v in fixed_params.items():\n",
    "        try:\n",
    "            fixed_params[k] = int(v)\n",
    "        except ValueError:\n",
    "            try:     \n",
    "                fixed_params[k] = float(v)\n",
    "            except ValueError:\n",
    "                if fixed_params[k] == 'None':\n",
    "                    fixed_params[k] = None \n",
    "                else:\n",
    "                    fixed_params[k] = str(v).lower()\n",
    "                pass\n",
    "    return fixed_params\n",
    "# datanew = data.copy()\n",
    "data_formatted = data.copy()\n",
    "data_formatted['parameters'] = data_formatted['parameters'].apply(lambda x: fix_params(x))\n",
    "\n",
    "data_formatted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add default parameters to parameter dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_extend_params(x):\n",
    "#     print(x)\n",
    "    x.parameters = extend_params(x.classifier,x.parameters)\n",
    "    return x\n",
    "data_formatted_ext = data_formatted.copy()\n",
    "data_formatted_ext = data_formatted_ext.apply(lambda x: df_extend_params(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_formatted_ext.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter out any parameter combinations that PennAI can't recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_param_combo(ml, params):\n",
    "    if params in pennai_ml_opts_ext[ml]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "print('unfiltered:',len(data_formatted_ext),'results with',\n",
    "     len(data_formatted_ext.parameters.apply(str).unique()),'unique parameters')\n",
    "data_formatted_ext_filtered = data_formatted_ext#.loc[data_formatted_ext.classifier=='SVC']\n",
    "print('calculating mask...')\n",
    "mask = []\n",
    "from tqdm import tqdm\n",
    "for _, row in tqdm(data_formatted_ext_filtered.iterrows()):\n",
    "    mask.append(valid_param_combo(row['classifier'],row['parameters']) )\n",
    "print('done with mask')\n",
    "# mask = mask | data_formatted_ext_filtered.classifier=='LogisticRegression'\n",
    "data_formatted_ext_filtered = data_formatted_ext_filtered.loc[mask]\n",
    "print('filtered data has',len(data_formatted_ext_filtered),'results with',\n",
    "     len(data_formatted_ext_filtered.parameters.apply(str).unique()),'unique parameters')\n",
    "data_formatted_ext_filtered.head()\n",
    "# data_filtered = data.loc[lambda x: valid_param_combo(i['classifier'],i['parameters']) for i in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_formatted_ext_filtered.classifier.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pennai_ml_opts:')\n",
    "print(pennai_ml_opts_ext['GradientBoostingClassifier'][0].keys(),len(pennai_ml_opts_ext['GradientBoostingClassifier'][0].keys()))\n",
    "print('data opts:')\n",
    "print(data_formatted_ext_filtered.loc[data_formatted_ext_filtered.classifier=='GradientBoostingClassifier'].parameters.values[0].keys())\n",
    "len(data_formatted_ext_filtered.loc[data_formatted_ext_filtered.classifier=='GradientBoostingClassifier'].parameters.values[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, dfg in data_formatted_ext_filtered.groupby('classifier'):\n",
    "    print(clf,'unique params combos:',len(dfg.parameters.apply(str).unique()))\n",
    "alg_params = data_formatted_ext_filtered['classifier']+'|'+data_formatted_ext_filtered['parameters'].apply(str)\n",
    "print(len(alg_params.unique()),'unique algorithm/parameter combinations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-prune parameters from knowledgebase that were added as defaults (not in PennAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_params(x):\n",
    "#     pdb.set_trace()\n",
    "    ml = x.classifier\n",
    "    params = x.parameters\n",
    "    param_opts = original_pennai_ml_opts[ml]\n",
    "    x.parameters = {k:v for k,v in params.items() if k in param_opts}\n",
    "    return x \n",
    "data_formatted_ext_filtered_pruned = data_formatted_ext_filtered.copy()\n",
    "data_formatted_ext_filtered_pruned = data_formatted_ext_filtered_pruned.apply(\n",
    "    lambda x: prune_params(x),axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, dfg in data_formatted_ext_filtered_pruned.groupby('classifier'):\n",
    "    print(clf,'unique params combos:',len(dfg.parameters.apply(str).unique()))\n",
    "alg_params = (data_formatted_ext_filtered_pruned['classifier']+'|'\n",
    "              +data_formatted_ext_filtered_pruned['parameters'].apply(str))\n",
    "print(len(alg_params.unique()),'unique algorithm/parameter combinations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subsample the SVC parameter results because they are so imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_formatted_ext_filtered_pruned_lessSVC = data_formatted_ext_filtered_pruned.copy()\n",
    "dfxfpl = data_formatted_ext_filtered_pruned_lessSVC\n",
    "C  = [0.001, 0.1, 1, 10]\n",
    "gamma = [0.01, 1.0, 100]\n",
    "coef0 = [0.0,1.0,10]\n",
    "\n",
    "svc = dfxfpl['classifier']=='SVC'\n",
    "mask = [False for g in svc]\n",
    "for n in C:\n",
    "    mask = mask | (svc & \n",
    "                   np.array(\n",
    "                       [p['C'] == n if 'C' in p.keys() else False for p in dfxfpl['parameters'].values]))\n",
    "mask = (mask | ~svc)\n",
    "dfxfpl = dfxfpl.loc[mask,:]\n",
    "\n",
    "svc = dfxfpl['classifier']=='SVC'\n",
    "mask = [False for g in svc]\n",
    "for n in gamma:\n",
    "    mask = mask | (svc &  np.array(\n",
    "                   [p['gamma'] == n if 'gamma' in p.keys() else False for p in dfxfpl['parameters'].values]))\n",
    "mask = (mask | ~svc)\n",
    "dfxfpl = dfxfpl.loc[mask,:]\n",
    "\n",
    "svc = dfxfpl['classifier']=='SVC'\n",
    "mask = [False for g in svc]\n",
    "for n in coef0:\n",
    "    mask = mask | (svc & np.array(\n",
    "        [p['coef0'] == n if 'coef0' in p.keys() else False for p in dfxfpl['parameters'].values]))\n",
    "mask = (mask | ~svc)\n",
    "dfxfpl = dfxfpl.loc[mask,:]\n",
    "\n",
    "for clf, dfg in dfxfpl.groupby('classifier'):\n",
    "    print(clf,'unique params combos:',len(dfg.parameters.apply(str).unique()))\n",
    "alg_params = (dfxfpl['classifier']+'|'\n",
    "              +dfxfpl['parameters'].apply(str))\n",
    "print(len(alg_params.unique()),'unique algorithm/parameter combinations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove big files since their metafeatures take forever to load\n",
    "# UPDATE: timing isn't an issue anymore since metafeatures for knowledgebases are provided by file. \n",
    "# no need to filter these out now.\n",
    "# data_formatted_ext_filtered_pruned_small = data_formatted_ext_filtered_pruned.copy()\n",
    "# #datasets to remove:\n",
    "# big_datasets = ['poker', 'kddcup', 'sleep', 'fars', 'mnist'] \n",
    "# # , 'connect-4', 'shuttle', 'adult', 'krkopt', \n",
    "# #                 'letter', 'magic', 'nursery', 'pendigits', 'coil2000', 'agaricus-lepiota','optdigits']\n",
    "# mask = np.array([d not in big_datasets for d in data_formatted_ext_filtered_pruned_small['dataset'].values])\n",
    "# data_formatted_ext_filtered_pruned_small  = data_formatted_ext_filtered_pruned_small.loc[mask,:]\n",
    "# print(len(data_formatted_ext_filtered_pruned_small['dataset'].unique()),'datasets left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write modified data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfxfpl),'total results')\n",
    "dfxfpl.rename(columns={'classifier':'algorithm'},inplace=True)\n",
    "dfxfpl.to_csv('sklearn-benchmark5-data-knowledgebase.tsv.gz',\n",
    "                                                compression='gzip',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a small knowledge base for testing\n",
    "test_data = dfxfpl.sample(frac=0.1)\n",
    "test_data.to_csv('sklearn-benchmark5-data-knowledgebase-small.tsv.gz',\n",
    "                                                compression='gzip',index=False,sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
