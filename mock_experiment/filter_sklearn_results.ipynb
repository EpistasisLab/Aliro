{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GradientBoostingClassifier': {'learning_rate': [0.01, 0.1, 1], 'subsample': [0.5, 1], 'min_samples_leaf': [10, 20, 5], 'max_depth': [1, 10, 5], 'min_samples_split': [10, 20, 5], 'n_estimators': [100, 250], 'max_features': ['log2', 'sqrt']}, 'SVC': {'tol': [0.0001, 0.001, 0.01, 0.1, 1e-05], 'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 25], 'kernel': ['poly', 'rbf']}, 'DecisionTreeClassifier': {'min_samples_leaf': [10, 20, 5], 'criterion': ['entropy', 'gini'], 'min_samples_split': [10, 20, 5], 'max_depth': [2, 4, 6, 8]}, 'LogisticRegression': {'dual': ['false', 'true'], 'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 25], 'penalty': ['l1', 'l2']}, 'KNeighborsClassifier': {'weights': ['distance', 'uniform'], 'p': [1, 2], 'n_neighbors': [1, 11, 3, 5, 7, 9]}, 'RandomForestClassifier': {'criterion': ['entropy', 'gini'], 'n_estimators': [100, 250], 'min_samples_leaf': [10, 20, 5], 'min_samples_split': [10, 20, 5], 'bootstrap': ['false', 'true'], 'max_features': ['log2', 'sqrt']}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# # set up dictionaries of parameter options for each learner\n",
    "param_opts = {\n",
    "    'DecisionTreeClassifier': {},\n",
    "    'GradientBoostingClassifier': {},\n",
    "    'KNeighborsClassifier': {},\n",
    "    'LogisticRegression': {},\n",
    "    'RandomForestClassifier': {},\n",
    "    'SVC': {}\n",
    "}\n",
    "ml_p = pd.read_csv('ml_p_options.csv')\n",
    "ml_p.rename(columns={'alg_name':'classifier'},inplace=True)\n",
    "for ml, df_ml in ml_p.groupby('classifier'):\n",
    "    for p, df_ml_p in df_ml.groupby('parameters'):\n",
    "        d = eval(p)\n",
    "        for keys,v in d.items():\n",
    "            if keys not in param_opts[ml].keys():\n",
    "                param_opts[ml][keys] = [v]\n",
    "            elif v not in param_opts[ml][keys]:\n",
    "                param_opts[ml][keys].append(v)\n",
    "print(param_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bill/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             dataset          classifier  \\\n",
      "0  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "1  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "2  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "3  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "4  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...  AdaBoostClassifier   \n",
      "\n",
      "                             parameters  accuracy   macrof1 bal_accuracy  \n",
      "0    learning_rate=0.01,n_estimators=10  0.479375  0.470857   0.479375.1  \n",
      "1   learning_rate=0.01,n_estimators=100  0.476875  0.476497     0.476875  \n",
      "2  learning_rate=0.01,n_estimators=1000  0.488125  0.488115     0.488125  \n",
      "3    learning_rate=0.01,n_estimators=50  0.483750  0.483652      0.48375  \n",
      "4   learning_rate=0.01,n_estimators=500  0.495625  0.495609     0.495625  \n",
      "loaded  166 datasets and  13 classifiers\n",
      "datasets ( 166 )\n",
      "classifiers ( 6 ): ['DecisionTreeClassifier' 'GradientBoostingClassifier'\n",
      " 'KNeighborsClassifier' 'LogisticRegression' 'RandomForestClassifier'\n",
      " 'SVC']\n",
      "parameters for  DecisionTreeClassifier ( 154 ): ['min_weight_fraction_leaf=0.0,max_features=0.1,criterion=entropy'\n",
      " 'min_weight_fraction_leaf=0.0,max_features=0.1,criterion=gini'\n",
      " 'min_weight_fraction_leaf=0.0,max_features=0.25,criterion=entropy'\n",
      " 'min_weight_fraction_leaf=0.0,max_features=0.25,criterion=gini'\n",
      " 'min_weight_fraction_leaf=0.0,max_features=0.5,criterion=entropy']\n",
      "parameters for  GradientBoostingClassifier ( 6301 ): ['loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.2'\n",
      " 'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.3'\n",
      " 'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.4'\n",
      " 'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.5'\n",
      " 'loss=deviance,learning_rate=0.01,n_estimators=10,max_depth=1,max_features=0.6']\n",
      "parameters for  KNeighborsClassifier ( 54 ): ['n_neighbors=1,weights=distance' 'n_neighbors=1,weights=uniform'\n",
      " 'n_neighbors=10,weights=distance' 'n_neighbors=10,weights=uniform'\n",
      " 'n_neighbors=100,weights=distance']\n",
      "parameters for  LogisticRegression ( 240 ): ['C=0.5,penalty=l1,fit_intercept=False,dual=False,'\n",
      " 'C=0.5,penalty=l1,fit_intercept=True,dual=False,'\n",
      " 'C=0.5,penalty=l2,fit_intercept=False,dual=False,'\n",
      " 'C=0.5,penalty=l2,fit_intercept=False,dual=True,'\n",
      " 'C=0.5,penalty=l2,fit_intercept=True,dual=False,']\n",
      "parameters for  RandomForestClassifier ( 770 ): ['n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.1,criterion=entropy'\n",
      " 'n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.1,criterion=gini'\n",
      " 'n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.25,criterion=entropy'\n",
      " 'n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.25,criterion=gini'\n",
      " 'n_estimators=10,min_weight_fraction_leaf=0.0,max_features=0.5,criterion=entropy']\n",
      "parameters for  SVC ( 1239 ): ['C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=0.0,'\n",
      " 'C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=0.1,'\n",
      " 'C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=0.5,'\n",
      " 'C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=1.0,'\n",
      " 'C=0.01,gamma=0.01,kernel=poly,degree=2,coef0=10.0,']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('sklearn-benchmark5-data-edited.tsv.gz', sep='\\t', names=['dataset',\n",
    "                                                                     'classifier',\n",
    "                                                                     'parameters',\n",
    "                                                                     'accuracy', \n",
    "                                                                     'macrof1',\n",
    "                                                                     'bal_accuracy']).fillna('')\n",
    "print(data.head())\n",
    "data['accuracy'] = data['accuracy'].apply(lambda x: round(x, 3))\n",
    "print('loaded ',data['dataset'].unique().shape[0],'datasets and ', data['classifier'].unique().shape[0],'classifiers')\n",
    "# subset data to classifiers used in PennAI\n",
    "pennai_classifiers = ['LogisticRegression', 'RandomForestClassifier', 'SVC', \n",
    "                      'KNeighborsClassifier', 'DecisionTreeClassifier', 'GradientBoostingClassifier']\n",
    "mask = np.array([c in pennai_classifiers for c in data['classifier'].values])\n",
    "data = data.loc[mask,:]\n",
    "print('datasets (',len(data['dataset'].unique()),')')\n",
    "print('classifiers (',len(data['classifier'].unique()),'):',data['classifier'].unique())\n",
    "for ml, df_g in data.groupby('classifier'):\n",
    "    print('parameters for ',ml,'(',len(df_g['parameters'].unique()),'):',df_g['parameters'].unique()[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def convert_params(params):\n",
    "    \"\"\"convert from sklearn-style parameter formatting to dictionary, PennAI style.\"\"\"\n",
    "    pdict = {}\n",
    "    for kv in params.split(','):\n",
    "        if len(kv)==0: continue\n",
    "#         print(kv.split('='))\n",
    "        pdict[str(kv.split('=')[0])] = kv.split('=')[1]\n",
    "    for k,v in pdict.items():\n",
    "        try:\n",
    "            pdict[k] = int(v)\n",
    "        except ValueError:\n",
    "            try:     \n",
    "                pdict[k] = float(v)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    return OrderedDict(sorted(pdict.items()))\n",
    "\n",
    "\n",
    "data['parameters'] = data['parameters'].apply(lambda x: convert_params(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for  DecisionTreeClassifier ( 154 ): OrderedDict([('criterion', 'entropy'), ('max_features', 0.1), ('min_weight_fraction_leaf', 0.0)])\n",
      "parameters for  GradientBoostingClassifier ( 6301 ): OrderedDict([('learning_rate', 0.01), ('loss', 'deviance'), ('max_depth', 1), ('max_features', 0.2), ('n_estimators', 10)])\n",
      "parameters for  KNeighborsClassifier ( 54 ): OrderedDict([('n_neighbors', 1), ('weights', 'distance')])\n",
      "parameters for  LogisticRegression ( 240 ): OrderedDict([('C', 0.5), ('dual', 'False'), ('fit_intercept', 'False'), ('penalty', 'l1')])\n",
      "parameters for  RandomForestClassifier ( 770 ): OrderedDict([('criterion', 'entropy'), ('max_features', 0.1), ('min_weight_fraction_leaf', 0.0), ('n_estimators', 10)])\n",
      "parameters for  SVC ( 1239 ): OrderedDict([('C', 0.01), ('coef0', 0.0), ('degree', 2), ('gamma', 0.01), ('kernel', 'poly')])\n"
     ]
    }
   ],
   "source": [
    "for ml, df_g in data.groupby('classifier'):\n",
    "    print('parameters for ',ml,'(',len(df_g['parameters'].apply(str).unique()),'):',\n",
    "           df_g['parameters'].apply(str).unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_param_combo(ml,params):\n",
    "#     print('ml',ml,type(ml).__name__)\n",
    "#     print('params',params,type(params).__name__)\n",
    "\n",
    "    for k,v in params.items():\n",
    "        if k in param_opts[ml].keys():\n",
    "            if v not in param_opts[ml][k]:\n",
    "#                 print('eliminating',params,'for',ml,'with',k,':',v)\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "mask = [valid_param_combo(row['classifier'],row['parameters']) for _, row in data.iterrows()]\n",
    "    \n",
    "data_filtered = data.loc[mask]\n",
    "\n",
    "# data_filtered = data.loc[lambda x: valid_param_combo(i['classifier'],i['parameters']) for i in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"{'criterion': 'gini', 'learning_rate': 50, 'kernel': 'sigmoid', 'weights': 'uniform', 'penalty': 'l2', 'loss': 'deviance', 'gamma': 50.0, 'degree': 2, 'min_weight_fraction_leaf': 0, 'coef0': 50.0, 'dual': 'True', 'fit_intercept': 'True', 'max_depth': 'None', 'max_features': 'sqrt', 'C': 0.01, 'n_estimators': 500, 'n_neighbors': 9}\"]\n"
     ]
    }
   ],
   "source": [
    "print(data[data['classifier']=='KNeighborsClassifier']['parameters'].apply(str).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macrof1</th>\n",
       "      <th>bal_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 0.1, ...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.507488</td>\n",
       "      <td>0.5075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 0.1, 'mi...</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.476040</td>\n",
       "      <td>0.47625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 0.25,...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.506832</td>\n",
       "      <td>0.506875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 0.25, 'm...</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.489993</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 0.5, ...</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512497</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dataset  \\\n",
       "175  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "176  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "177  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "178  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "179  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_ED...   \n",
       "\n",
       "                 classifier  \\\n",
       "175  DecisionTreeClassifier   \n",
       "176  DecisionTreeClassifier   \n",
       "177  DecisionTreeClassifier   \n",
       "178  DecisionTreeClassifier   \n",
       "179  DecisionTreeClassifier   \n",
       "\n",
       "                                            parameters  accuracy   macrof1  \\\n",
       "175  {'criterion': 'entropy', 'max_features': 0.1, ...     0.507  0.507488   \n",
       "176  {'criterion': 'gini', 'max_features': 0.1, 'mi...     0.476  0.476040   \n",
       "177  {'criterion': 'entropy', 'max_features': 0.25,...     0.507  0.506832   \n",
       "178  {'criterion': 'gini', 'max_features': 0.25, 'm...     0.490  0.489993   \n",
       "179  {'criterion': 'entropy', 'max_features': 0.5, ...     0.512  0.512497   \n",
       "\n",
       "    bal_accuracy  \n",
       "175       0.5075  \n",
       "176      0.47625  \n",
       "177     0.506875  \n",
       "178         0.49  \n",
       "179       0.5125  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_filtered shape:  (113740, 6)\n",
      "datasets ( 165 )\n",
      "classifiers ( 5 ): ['DecisionTreeClassifier' 'GradientBoostingClassifier'\n",
      " 'KNeighborsClassifier' 'RandomForestClassifier' 'SVC']\n",
      "parameters for  DecisionTreeClassifier ( 154 ): [\"OrderedDict([('criterion', 'entropy'), ('max_features', 0.1), ('min_weight_fraction_leaf', 0.0)])\"\n",
      " \"OrderedDict([('criterion', 'gini'), ('max_features', 0.1), ('min_weight_fraction_leaf', 0.0)])\"\n",
      " \"OrderedDict([('criterion', 'entropy'), ('max_features', 0.25), ('min_weight_fraction_leaf', 0.0)])\"\n",
      " \"OrderedDict([('criterion', 'gini'), ('max_features', 0.25), ('min_weight_fraction_leaf', 0.0)])\"\n",
      " \"OrderedDict([('criterion', 'entropy'), ('max_features', 0.5), ('min_weight_fraction_leaf', 0.0)])\"]\n",
      "parameters for  GradientBoostingClassifier ( 36 ): [\"OrderedDict([('learning_rate', 0.01), ('loss', 'deviance'), ('max_depth', 1), ('max_features', 'log2'), ('n_estimators', 100)])\"\n",
      " \"OrderedDict([('learning_rate', 0.01), ('loss', 'deviance'), ('max_depth', 1), ('max_features', 'sqrt'), ('n_estimators', 100)])\"\n",
      " \"OrderedDict([('learning_rate', 0.01), ('loss', 'deviance'), ('max_depth', 10), ('max_features', 'log2'), ('n_estimators', 100)])\"\n",
      " \"OrderedDict([('learning_rate', 0.01), ('loss', 'deviance'), ('max_depth', 10), ('max_features', 'sqrt'), ('n_estimators', 100)])\"\n",
      " \"OrderedDict([('learning_rate', 0.01), ('loss', 'deviance'), ('max_depth', 5), ('max_features', 'log2'), ('n_estimators', 100)])\"]\n",
      "parameters for  KNeighborsClassifier ( 12 ): [\"OrderedDict([('n_neighbors', 1), ('weights', 'distance')])\"\n",
      " \"OrderedDict([('n_neighbors', 1), ('weights', 'uniform')])\"\n",
      " \"OrderedDict([('n_neighbors', 11), ('weights', 'distance')])\"\n",
      " \"OrderedDict([('n_neighbors', 11), ('weights', 'uniform')])\"\n",
      " \"OrderedDict([('n_neighbors', 3), ('weights', 'distance')])\"]\n",
      "parameters for  RandomForestClassifier ( 44 ): [\"OrderedDict([('criterion', 'entropy'), ('max_features', 'log2'), ('min_weight_fraction_leaf', 0.0), ('n_estimators', 100)])\"\n",
      " \"OrderedDict([('criterion', 'gini'), ('max_features', 'log2'), ('min_weight_fraction_leaf', 0.0), ('n_estimators', 100)])\"\n",
      " \"OrderedDict([('criterion', 'entropy'), ('max_features', 'sqrt'), ('min_weight_fraction_leaf', 0.0), ('n_estimators', 100)])\"\n",
      " \"OrderedDict([('criterion', 'gini'), ('max_features', 'sqrt'), ('min_weight_fraction_leaf', 0.0), ('n_estimators', 100)])\"\n",
      " \"OrderedDict([('criterion', 'entropy'), ('max_features', 'log2'), ('min_weight_fraction_leaf', 0.05), ('n_estimators', 100)])\"]\n",
      "parameters for  SVC ( 600 ): [\"OrderedDict([('C', 0.01), ('coef0', 0.0), ('degree', 2), ('gamma', 0.01), ('kernel', 'poly')])\"\n",
      " \"OrderedDict([('C', 0.01), ('coef0', 0.1), ('degree', 2), ('gamma', 0.01), ('kernel', 'poly')])\"\n",
      " \"OrderedDict([('C', 0.01), ('coef0', 0.5), ('degree', 2), ('gamma', 0.01), ('kernel', 'poly')])\"\n",
      " \"OrderedDict([('C', 0.01), ('coef0', 1.0), ('degree', 2), ('gamma', 0.01), ('kernel', 'poly')])\"\n",
      " \"OrderedDict([('C', 0.01), ('coef0', 10.0), ('degree', 2), ('gamma', 0.01), ('kernel', 'poly')])\"]\n"
     ]
    }
   ],
   "source": [
    "print('data_filtered shape: ', data_filtered.shape)\n",
    "print('datasets (',len(data_filtered['dataset'].unique()),')')\n",
    "print('classifiers (',len(data_filtered['classifier'].unique()),'):',data_filtered['classifier'].unique())\n",
    "for ml, df_g in data_filtered.groupby('classifier'):\n",
    "    print('parameters for ',ml,'(',len(df_g['parameters'].apply(str).unique()),'):',\n",
    "           df_g['parameters'].apply(str).unique()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove big datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 datasets left\n"
     ]
    }
   ],
   "source": [
    "#datasets to remove:\n",
    "big_datasets = ['poker', 'kddcup', 'sleep', 'fars', 'mnist', 'connect-4', 'shuttle', 'adult', 'krkopt', \n",
    "                'letter', 'magic', 'nursery', 'pendigits', 'coil2000', 'agaricus-lepiota','optdigits']\n",
    "mask = np.array([d not in big_datasets for d in data_filtered['dataset'].values])\n",
    "clean_data = data_filtered.loc[mask,:]\n",
    "clean_data.groupby('dataset').count()\n",
    "print(len(clean_data['dataset'].unique()),'datasets left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove alg-params that don't cover all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 0 algorithm-parameter combinations\n",
      "new size: 35850\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macrof1</th>\n",
       "      <th>bal_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>23100</td>\n",
       "      <td>23100</td>\n",
       "      <td>23100</td>\n",
       "      <td>23100</td>\n",
       "      <td>23100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>2700</td>\n",
       "      <td>2700</td>\n",
       "      <td>2700</td>\n",
       "      <td>2700</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>6600</td>\n",
       "      <td>6600</td>\n",
       "      <td>6600</td>\n",
       "      <td>6600</td>\n",
       "      <td>6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dataset  parameters  accuracy  macrof1  \\\n",
       "classifier                                                           \n",
       "DecisionTreeClassifier        23100       23100     23100    23100   \n",
       "GradientBoostingClassifier     2700        2700      2700     2700   \n",
       "KNeighborsClassifier           1800        1800      1800     1800   \n",
       "RandomForestClassifier         6600        6600      6600     6600   \n",
       "SVC                            1650        1650      1650     1650   \n",
       "\n",
       "                            bal_accuracy  \n",
       "classifier                                \n",
       "DecisionTreeClassifier             23100  \n",
       "GradientBoostingClassifier          2700  \n",
       "KNeighborsClassifier                1800  \n",
       "RandomForestClassifier              6600  \n",
       "SVC                                 1650  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.loc[:, 'algorithm-parameters'] = (                                             \n",
    "                                       clean_data['classifier'].values + '|' +                     \n",
    "                                       clean_data['parameters'].apply(str).values) \n",
    "all_datasets = np.unique(clean_data['dataset'].values)\n",
    "algp_toremove = []\n",
    "for algp, group in clean_data.groupby('algorithm-parameters'):\n",
    "    if (group['dataset'].count()<150):\n",
    "        #print(algp, '\\n\\t is missing results for', [d for d in all_datasets if d not in np.unique(group['dataset'])])\n",
    "        #print('removing',algp)\n",
    "        algp_toremove.append(algp)\n",
    "        \n",
    "mask = np.array([ap not in algp_toremove for ap in clean_data['algorithm-parameters'].values])\n",
    "print('removing',np.sum(~mask),'algorithm-parameter combinations')\n",
    "clean_data = clean_data.loc[mask,:]\n",
    "print('new size:',len(clean_data))\n",
    "clean_data.drop('algorithm-parameters',axis=1,inplace=True)\n",
    "\n",
    "clean_data.groupby('classifier').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write modified data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_csv('sklearn-benchmark5-data-mock_experiment.tsv.gz',compression='gzip',index=False,sep='\\t',\n",
    "                  header=['dataset',\n",
    "                                 'algorithm',\n",
    "                                 'parameters',\n",
    "                                 'accuracy', \n",
    "                                 'macrof1',\n",
    "                                 'bal_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
