{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# # set up dictionaries of parameter options for each learner\n",
    "param_opts = {\n",
    "    'DecisionTreeClassifier': {},\n",
    "    'GradientBoostingClassifier': {},\n",
    "    'KNeighborsClassifier': {},\n",
    "    'LogisticRegression': {},\n",
    "    'RandomForestClassifier': {},\n",
    "    'SVC': {}\n",
    "}\n",
    "ml_p = pd.read_csv('ml_p_options.csv')\n",
    "ml_p.rename(columns={'alg_name':'classifier'},inplace=True)\n",
    "for ml, df_ml in ml_p.groupby('classifier'):\n",
    "    for p, df_ml_p in df_ml.groupby('parameters'):\n",
    "        d = eval(p)\n",
    "        for keys,v in d.items():\n",
    "            if keys not in param_opts[ml].keys():\n",
    "                param_opts[ml][keys] = [v]\n",
    "            elif v not in param_opts[ml][keys]:\n",
    "                param_opts[ml][keys].append(v)\n",
    "print(param_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('sklearn-benchmark5-data-edited.tsv.gz', sep='\\t', names=['dataset',\n",
    "                                                                     'classifier',\n",
    "                                                                     'parameters',\n",
    "                                                                     'accuracy', \n",
    "                                                                     'macrof1',\n",
    "                                                                     'bal_accuracy']).fillna('')\n",
    "print(data.head())\n",
    "data['accuracy'] = data['accuracy'].apply(lambda x: round(x, 3))\n",
    "print('loaded ',data['dataset'].unique().shape[0],'datasets and ', data['classifier'].unique().shape[0],'classifiers')\n",
    "# subset data to classifiers used in PennAI\n",
    "pennai_classifiers = ['LogisticRegression', 'RandomForestClassifier', 'SVC', \n",
    "                      'KNeighborsClassifier', 'DecisionTreeClassifier', 'GradientBoostingClassifier']\n",
    "mask = np.array([c in pennai_classifiers for c in data['classifier'].values])\n",
    "data = data.loc[mask,:]\n",
    "print('datasets (',len(data['dataset'].unique()),')')\n",
    "print('classifiers (',len(data['classifier'].unique()),'):',data['classifier'].unique())\n",
    "for ml, df_g in data.groupby('classifier'):\n",
    "    print('parameters for ',ml,'(',len(df_g['parameters'].unique()),'):',df_g['parameters'].unique()[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner = {}\n",
    "winner_datasets = {}\n",
    "import numpy as np\n",
    "for d, df in data.groupby('dataset'):\n",
    "    df['bal_accuracy'] = df['bal_accuracy'].apply(pd.to_numeric)\n",
    "    best_score = df['bal_accuracy'].max()\n",
    "    for clf, dfg in df.groupby('classifier'):\n",
    "        wins = np.any((best_score - dfg.bal_accuracy)/best_score <= 0.01)\n",
    "        if wins:\n",
    "            if clf in winner:\n",
    "                winner[clf] += 1\n",
    "                winner_datasets[clf].append(d)\n",
    "            else:\n",
    "                winner[clf] = 1\n",
    "                winner_datasets[clf] = [d]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# print(winner)\n",
    "# print(winner_datasets)\n",
    "plt.bar(list(winner.keys()),list(winner.values()))\n",
    "plt.xticks(rotation=90)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = ['n_estimators='+str(n) for n in [100,500,1000]]\n",
    "max_depth = ['max_depth='+str(d) for d in [4,6,10]]\n",
    "max_features = ['max_features='+str(f) for f in ['sqrt','log2']]\n",
    "\n",
    "gbc = data['classifier']=='GradientBoostingClassifier'\n",
    "mask = [False for g in gbc]\n",
    "for n in n_est:\n",
    "    mask = mask | (gbc & np.array([n in p for p in data['parameters'].values]))\n",
    "mask = (mask | ~gbc)\n",
    "data = data.loc[mask,:]\n",
    "\n",
    "gbc = data['classifier']=='GradientBoostingClassifier'\n",
    "mask = [False for g in gbc]\n",
    "for n in max_depth:\n",
    "    mask = mask | (gbc & np.array([n in p for p in data['parameters'].values]))\n",
    "mask = (mask | ~gbc)\n",
    "data = data.loc[mask,:]\n",
    "\n",
    "gbc = data['classifier']=='GradientBoostingClassifier'\n",
    "mask = [False for g in gbc]\n",
    "for n in max_features:\n",
    "    mask = mask | (gbc & np.array([n in p for p in data['parameters'].values]))\n",
    "mask = (mask | ~gbc)\n",
    "data = data.loc[mask,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce Random Forest n_estimators\n",
    "\n",
    "rfc = data['classifier']=='RandomForestClassifier'\n",
    "mask = [False for g in rfc]\n",
    "for n in n_est:\n",
    "    mask = mask | (rfc & np.array([n in p for p in data['parameters'].values]))\n",
    "mask = (mask | ~rfc)\n",
    "data = data.loc[mask,:]\n",
    "\n",
    "max_features = ['max_features='+str(f) for f in ['sqrt','log2',None]]\n",
    "rfc = data['classifier']=='RandomForestClassifier'\n",
    "mask = [False for g in rfc]\n",
    "for n in max_features:\n",
    "    mask = mask | (rfc & np.array([n in p for p in data['parameters'].values]))\n",
    "mask = (mask | ~rfc)\n",
    "data = data.loc[mask,:]\n",
    "\n",
    "data.groupby('classifier').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def convert_params(params):\n",
    "    \"\"\"convert from sklearn-style parameter formatting to dictionary, PennAI style.\"\"\"\n",
    "    pdict = {}\n",
    "    for kv in params.split(','):\n",
    "        if len(kv)==0: continue\n",
    "#         print(kv.split('='))\n",
    "        pdict[str(kv.split('=')[0])] = kv.split('=')[1]\n",
    "    for k,v in pdict.items():\n",
    "        try:\n",
    "            pdict[k] = int(v)\n",
    "        except ValueError:\n",
    "            try:     \n",
    "                pdict[k] = float(v)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    return OrderedDict(sorted(pdict.items()))\n",
    "\n",
    "\n",
    "data['parameters'] = data['parameters'].apply(lambda x: convert_params(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ml, df_g in data.groupby('classifier'):\n",
    "    print('example parameters for ',ml,'(',len(df_g['parameters'].apply(str).unique()),'):',\n",
    "           df_g['parameters'].apply(str).unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def valid_param_combo(ml,params):\n",
    "#     print('ml',ml,type(ml).__name__)\n",
    "#     print('params',params,type(params).__name__)\n",
    "\n",
    "#    for k,v in params.items():\n",
    "#        if k in param_opts[ml].keys():\n",
    "#            if param_opts[ml][k] is int:\n",
    "#                try:\n",
    "#                    if int(v) in param_opts[ml][k]:\n",
    "#                        return True\n",
    "#                except: \n",
    "#                    return False\n",
    "#            elif param_opts[ml][k] is float:\n",
    "#                try:\n",
    "#                    if float(v) in param_opts[ml][k]:\n",
    "#                        return True\n",
    "#                except: \n",
    "#                    return False\n",
    "#            elif v not in param_opts[ml][k]:\n",
    "##                 if ml == 'LogisticRegression' and k=='C':\n",
    "##                     print('eliminating',params,'for',ml,'with',k,':',v)\n",
    "#                    return False\n",
    "#    return True\n",
    "#\n",
    "#mask = [valid_param_combo(row['classifier'],row['parameters']) for _, row in data.iterrows()]\n",
    "#mask = mask | data.classifier=='LogisticRegression'\n",
    "#data_filtered = data.loc[mask]\n",
    "#\n",
    "## data_filtered = data.loc[lambda x: valid_param_combo(i['classifier'],i['parameters']) for i in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ml, df_g in data.groupby('classifier'):\n",
    "    print('example parameters for ',ml,'(',len(df_g['parameters'].apply(str).unique()),'):',\n",
    "           df_g['parameters'].apply(str).unique()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how many winners of each algorithm are there? (winning = < 1% away from best score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner = {}\n",
    "winner_datasets = {}\n",
    "import numpy as np\n",
    "for d, df in data.groupby('dataset'):\n",
    "    df['bal_accuracy'] = df['bal_accuracy'].apply(pd.to_numeric)\n",
    "    best_score = df['bal_accuracy'].max()\n",
    "    for clf, dfg in df.groupby('classifier'):\n",
    "        wins = np.any((best_score - dfg.bal_accuracy)/best_score <= 0.01)\n",
    "        if wins:\n",
    "            if clf in winner:\n",
    "                winner[clf] += 1\n",
    "                winner_datasets[clf].append(d)\n",
    "            else:\n",
    "                winner[clf] = 1\n",
    "                winner_datasets[clf] = [d]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(winner)\n",
    "print(winner_datasets)\n",
    "plt.bar(list(winner.keys()),list(winner.values()))\n",
    "plt.xticks(rotation=90)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(winner)\n",
    "print(winner_datasets)\n",
    "plt.bar(list(winner.keys()),list(winner.values()))\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "other_winners = [d for d in [da for k,da in winner_datasets.items() if k != 'GradientBoostingClassifier' ]]\n",
    "other_winners = list(itertools.chain.from_iterable(other_winners))\n",
    "print(other_winners) \n",
    "only_gbc = [d for d in winner_datasets['GradientBoostingClassifier'] \n",
    "            if d not in other_winners]\n",
    "print(only_gbc)\n",
    "len(only_gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove datasets where GBC is the only winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data.dataset.isin(only_gbc)]\n",
    "print('# datasets left:',len(data.dataset.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data['classifier']=='KNeighborsClassifier']['parameters'].apply(str).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data_filtered shape: ', data_filtered.shape)\n",
    "print('datasets (',len(data_filtered['dataset'].unique()),')')\n",
    "print('classifiers (',len(data_filtered['classifier'].unique()),'):',data_filtered['classifier'].unique())\n",
    "for ml, df_g in data_filtered.groupby('classifier'):\n",
    "    print('parameters for ',ml,'(',len(df_g['parameters'].apply(str).unique()),'):',\n",
    "           df_g['parameters'].apply(str).unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data_filtered shape: ', data_filtered.shape)\n",
    "print('datasets (',len(data_filtered['dataset'].unique()),')')\n",
    "print('classifiers (',len(data_filtered['classifier'].unique()),'):',data_filtered['classifier'].unique())\n",
    "for ml, df_g in data_filtered.groupby('classifier'):\n",
    "    print('parameters for ',ml,'(',len(df_g['parameters'].apply(str).unique()),'):',\n",
    "           df_g['parameters'].apply(str).unique()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove big datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data\n",
    "#datasets to remove:\n",
    "big_datasets = ['poker', 'kddcup', 'sleep', 'fars', 'mnist', 'connect-4', 'shuttle', 'adult', 'krkopt', \n",
    "                'letter', 'magic', 'nursery', 'pendigits', 'coil2000', 'agaricus-lepiota','optdigits']\n",
    "mask = np.array([d not in big_datasets for d in data_filtered['dataset'].values])\n",
    "clean_data = data_filtered.loc[mask,:]\n",
    "clean_data.groupby('dataset').count()\n",
    "print(len(clean_data['dataset'].unique()),'datasets left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove alg-params that don't cover all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.loc[:, 'algorithm-parameters'] = (                                             \n",
    "                                       clean_data['classifier'].values + '|' +                     \n",
    "                                       clean_data['parameters'].apply(str).values) \n",
    "all_datasets = np.unique(clean_data['dataset'].values)\n",
    "nd = len(all_datasets)\n",
    "algp_toremove = []\n",
    "for algp, group in clean_data.groupby('algorithm-parameters'):\n",
    "    if (group['dataset'].count()<nd):\n",
    "        #print(algp, '\\n\\t is missing results for', [d for d in all_datasets if d not in np.unique(group['dataset'])])\n",
    "        #print('removing',algp)\n",
    "        algp_toremove.append(algp)\n",
    "        \n",
    "mask = np.array([ap not in algp_toremove for ap in clean_data['algorithm-parameters'].values])\n",
    "print('removing',np.sum(~mask),'algorithm-parameter combinations')\n",
    "clean_data = clean_data.loc[mask,:]\n",
    "print('new size:',len(clean_data))\n",
    "clean_data.drop('algorithm-parameters',axis=1,inplace=True)\n",
    "\n",
    "clean_data.groupby('classifier').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner = {}\n",
    "winner_datasets = {}\n",
    "import numpy as np\n",
    "for d, df in clean_data.groupby('dataset'):\n",
    "    df['bal_accuracy'] = df['bal_accuracy'].apply(pd.to_numeric)\n",
    "    best_score = df['bal_accuracy'].max()\n",
    "    for clf, dfg in df.groupby('classifier'):\n",
    "        wins = np.any((best_score - dfg.bal_accuracy)/best_score <= 0.01)\n",
    "        if wins:\n",
    "            if clf in winner:\n",
    "                winner[clf] += 1\n",
    "                winner_datasets[clf].append(d)\n",
    "            else:\n",
    "                winner[clf] = 1\n",
    "                winner_datasets[clf] = [d]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(winner)\n",
    "print(winner_datasets)\n",
    "plt.bar(list(winner.keys()),list(winner.values()))\n",
    "plt.xticks(rotation=90)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ml, df_g in clean_data.groupby('classifier'):\n",
    "    print('example parameters for ',ml,'(',len(df_g['parameters'].apply(str).unique()),'):',\n",
    "           df_g['parameters'].apply(str).unique()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write modified data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_csv('sklearn-benchmark5-data-mock_experiment.tsv.gz',compression='gzip',index=False,sep='\\t',\n",
    "                  header=['dataset',\n",
    "                                 'algorithm',\n",
    "                                 'parameters',\n",
    "                                 'accuracy', \n",
    "                                 'macrof1',\n",
    "                                 'bal_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
