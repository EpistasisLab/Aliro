{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "from glob import glob\n",
    "\n",
    "frames = []\n",
    "for f in glob('results/r0/experiment_spiked_results*1000.csv'):\n",
    "    df = pd.read_csv(f)\n",
    "    df['winner'] = f.split('_wins')[0].split('_')[-1]\n",
    "#     df['n_init'] = f.split('ninit-')[-1].split('_')[0]\n",
    "#     df['n_recs'] = f.split('nrecs-')[-1].split('_')[0]\n",
    "    frames.append(df)\n",
    "df_exp = pd.concat(frames)\n",
    "print(df_exp[:5])\n",
    "print(df_exp.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# balanced accuracy deltas for all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sb.set_palette('colorblind',3)\n",
    "recs_count = len(df_exp.n_recs.unique())\n",
    "init_count = len(df_exp.n_init.unique())\n",
    "import numpy as np\n",
    "\n",
    "for winner,dfg in df_exp.groupby('winner'):\n",
    "    h = plt.figure(figsize=(10,10))\n",
    "    h.suptitle(winner+' spike')\n",
    "    i = 1\n",
    "    for nrecs,dfr in dfg.groupby('n_recs'):\n",
    "        for ninit,dfi in dfr.groupby('n_init'):\n",
    "            ax = h.add_subplot(recs_count, init_count, i)\n",
    "            sb.pointplot(data=dfi,\n",
    "                         x='iteration',y='delta_bal_accuracy',\n",
    "                         hue='recommender',\n",
    "                         scatter=False,\n",
    "                         ax = ax,\n",
    "                         n_boot=100,\n",
    "                         estimator=np.median)\n",
    "            name = 'nrecs='+str(nrecs)+', ninit='+str(ninit)\n",
    "            ax.set_title(name)\n",
    "            i += 1\n",
    "    h.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(winner+'_spiked_accuracy_comparison.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_exp['trial'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# generate figure of heatmap showing counts of which ML methods are recommended over time\n",
    "# experiment = '../experiment_sklearn-benchmark5-data-mock_experimentknn-random-average-meta_10recs_200trials_10init.csv'\n",
    "# experiment = '../experiment_random-average_100recs_500trials_1init.csv'\n",
    "accumulate = False\n",
    "\n",
    "df = pd.read_csv(experiment)\n",
    "n_trials = df['trial'].max()\n",
    "ave_count_mat = np.zeros((len(df['ml-rec'].unique()),len(df['iteration'].unique())))                     \n",
    "rand_count_mat = np.zeros((len(df['ml-rec'].unique()),len(df['iteration'].unique())))\n",
    "algs = list(df['ml-rec'].unique())\n",
    "iterations = df['iteration'].unique()\n",
    "print('algs:',algs)\n",
    "print('ave_count_mat',ave_count_mat.shape)\n",
    "# recommenders = ['random','average','meta']\n",
    "recommenders = df.recommender.unique()\n",
    "for recommender in recommenders:\n",
    "    ave_count_mat = np.zeros((len(df['ml-rec'].unique()),len(df['iteration'].unique())))                     \n",
    "    rand_count_mat = np.zeros((len(df['ml-rec'].unique()),len(df['iteration'].unique())))\n",
    "    dfa = df.loc[df['recommender']==recommender,:]\n",
    "\n",
    "    dfa.groupby('iteration').count() #.groupby('ml-rec').count()\n",
    "\n",
    "    for index,row in dfa.iterrows():\n",
    "        ave_count_mat[algs.index(row['ml-rec']),row['iteration']] += 1/n_trials\n",
    "    # cumulative sum\n",
    "    if accumulate:\n",
    "        for i,a in enumerate(ave_count_mat): \n",
    "            ave_count_mat[i] = np.cumsum(a)\n",
    "    #print('ave_count_mat:',ave_count_mat)\n",
    "\n",
    "    h = plt.figure(figsize=(10, 15))\n",
    "    ax = h.gca()\n",
    "    tmp = ax.matshow(ave_count_mat,cmap=plt.cm.coolwarm)\n",
    "    # sb.heatmap(ave_count_mat)#,\n",
    "               #cmap=sb.cubehelix_palette(500, light=0.95, dark=0.15),\n",
    "    #            square=False, annot=True, vmin=0., vmax=1.0,\n",
    "    #            xticklabels=iterations, yticklabels=algs, cbar=False)\n",
    "    cbar=plt.colorbar(tmp,ax=ax,orientation='vertical',shrink=0.1)\n",
    "    cbar.set_label('Recommendations')\n",
    "    ax.set_yticks(np.arange(len(algs)))\n",
    "    ax.set_yticklabels(algs)\n",
    "    ax.set_xlabel('Dataset', fontsize=8)\n",
    "    ax.set_ylabel(recommender + ' Recommender', fontsize=12)\n",
    "    #plt.title('ML Recommendations over many datasets', fontsize=18)\n",
    "    ax.set_aspect(4)\n",
    "    h.tight_layout()\n",
    "    if accumulate:\n",
    "        h.savefig(experiment[:-4]+'_'+recommender+'_heatmap_cumulative.pdf', bbox_inches='tight')\n",
    "    else:\n",
    "        h.savefig(experiment[:-4]+'_'+recommender+'_heatmap.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
